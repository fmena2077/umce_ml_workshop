{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Herramientas de Data Science para el análisis de Datos en Salud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hoy la ciencia de datos es un must para todas las disciplinas\n",
    "\n",
    "Hoy en día el uso de data science en diferentes disciplinas es una necesidad/requerimiento. El gran volumen y variedad de los datos obliga a que los especialistas conozcan y manejen herramientas computacionales para el correcto análisis de los datos e interpretación de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Estas son notas para el orador\n",
    "- Preferiblemete deben estar escritas en Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/motionsense'\n",
    "subject_data = 'data_subjects_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, subject_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EDA Usuarios\n",
    "\n",
    "Hacer histograma de los datos de los sujetos de experimentación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EDA Datos de Movimiento\n",
    "\n",
    "Las clases de movimientos registradas son las siguientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [c for c in os.listdir(os.path.join(data_dir, 'motion_data'))]\n",
    "classes = {'dws': 1,'jog': 2,'sit': 3,'std': 4,'ups': 5,'wlk': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar y verificar el registro para uno de los sujetos en estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_filename = os.path.join(data_dir, 'motion_data', 'dws_1', 'sub_{}.csv'.format(1))\n",
    "print(mot_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mot = pd.read_csv(mot_filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num registros: {} - Num. Medidas: {}'.format(df_mot.shape[0], df_mot.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas registradas\n",
    "for f in df_mot.columns:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motion(df, suptitle=None, nrows=4, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(5*ncols, 2.5*nrows))\n",
    "    \n",
    "    for i, f in enumerate(df.columns):\n",
    "        \n",
    "        row = i % nrows\n",
    "        col = i % ncols\n",
    "\n",
    "        ax[row, col].plot(df[f], label=f)\n",
    "        ax[row, col].set_title(f)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.suptitle('' if not suptitle else suptitle)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_motion(df_mot, 'dws_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_motions(folders, subject):\n",
    "    \"\"\"\n",
    "    This method plots all the behaviors for one subject.\n",
    "    \n",
    "    \"\"\"\n",
    "    for f in folders:\n",
    "        mot_filename = os.path.join(data_dir, 'motion_data', f, 'sub_{}.csv'.format(subject))\n",
    "        df_mot = pd.read_csv(mot_filename, index_col=0)\n",
    "        plot_motion(df_mot, 'Subjetc: {} - Class: {}'.format(subject, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_motions(dir_list, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracción de Características\n",
    "\n",
    "Extraeremos características desde cada una de las medidas y para cada uno de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "f_name = []\n",
    "\n",
    "for f in dir_list:\n",
    "\n",
    "    for u in pd.unique(df['code']).tolist():\n",
    "\n",
    "        mot_filename = os.path.join(data_dir, 'motion_data', f, 'sub_{}.csv'.format(u))\n",
    "        df_mot = pd.read_csv(mot_filename, index_col=0)\n",
    "        c, _ = f.split('_')\n",
    "        \n",
    "        feats = []\n",
    "        feats.extend(df_mot.mean(axis=0).tolist())\n",
    "        feats.extend(df_mot.std(axis=0).tolist())\n",
    "        feats.extend(df_mot.median(axis=0).tolist())\n",
    "        feats.extend(df_mot.skew(axis=0).tolist())\n",
    "        feats.extend(df_mot.kurtosis(axis=0).tolist())\n",
    "        feats.extend([classes[c]])\n",
    "\n",
    "        features.append(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Separamos características y targets\"\"\"\n",
    "\n",
    "features = pd.DataFrame(np.array(features))\n",
    "\n",
    "targets = features[features.columns[-1]]\n",
    "features = features[features.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos matrix de correlación\n",
    "corr_matrix = features.[].corr().abs()\n",
    "\n",
    "# Seleccionamos el triangulo superior de la matriz de correlación\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Encontramos aquellas columnas cuya correlación es mayor a 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features \n",
    "features = features.drop(features[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del Desempeño\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hold-Out\n",
    "\n",
    "Consiste en dividir la base de datos en una parte para el entrenamiento del modelo y otra parte para la evaluación del rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Existen reglas nemotécnicas y proporciones estándares:\n",
    "- Entrenamiento: 2/3, Evaluación: 1/3\n",
    "- Entrenamiento: 70%, Evaluación: 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    features[features.columns[:-1]], features[features.columns[-1]], \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ejemplos de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definamos una función para visualizar la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, targets=None, normalize=True, figsize=(7, 6)):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculamos el accuracy para el clasificador\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    \n",
    "    if normalize:\n",
    "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n",
    "        \n",
    "    df_cm = pd.DataFrame(cm, columns=targets, index=targets)\n",
    "    df_cm.index.name = 'Clase Real'\n",
    "    df_cm.columns.name = 'Clase Predicha'\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title('Accuracy: {:0.2f} - Error Rate: {:0.2f}'.format(accuracy, misclass), y=1.05)\n",
    "    sns.set(font_scale=1.4)  # for label size\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 10}, ax=ax)  # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_precision_recall(y_test, pred, targets):\n",
    "    \"\"\"\n",
    "    Esta función visualiza las métricas de Precisión, Recall y F-Score retornadas\n",
    "    por la función de sklearn precision_recall_fscore_support().\n",
    "    \n",
    "    \"\"\"\n",
    "    metrics = ['Precision', 'Recall', 'F-Score', 'Support']\n",
    "    prf = precision_recall_fscore_support(y_test, pred)\n",
    "    prf = np.array([np.round(m, 2) for m in prf])\n",
    "    prf = pd.DataFrame(prf, columns=targets, index=metrics)\n",
    "\n",
    "    return prf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de Decisión\n",
    "\n",
    "Para este ejemploi, utilizaremos un árbol con una profundidad máxima de $3$. Recordemos generar un árbol muy profundo puede generar la pérdida de generalidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "dtree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree.export import export_text\n",
    "r = export_text(dtree)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generamos una nueva figura y graficamos el árbol generado.\n",
    "\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
    "plot_tree(dtree, filled=True, fontsize=10, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Revisamos las primeras cinco predicciones \n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(classes.keys())\n",
    "pd.DataFrame(confusion_matrix(pred, y_test), columns=targets, index=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test), targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_precision_recall(y_test, pred, targets=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-NN\n",
    "\n",
    "Algunas consideraciones:\n",
    "\n",
    "- Para un clasificador K-NN los atributos deben ser reales, es decir, $X \\in R^{m,n}$, donde: ```m``` es el número de filas de los datos y ```n``` es el número de atributos de los datos.\n",
    "    \n",
    "- También, debemos considerar escalar los atributos para remover el efecto de las magnitudes en cada dimensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # Creamos una instancia del escalador\n",
    "scaler.fit(x_train)  # Calculamos la media y desviación estándar\n",
    "\n",
    "x_train_sc = scaler.transform(x_train) # Transformamos los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia del clasificador K-NN y \"entrenamos\" el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='auto', n_jobs=2)\n",
    "knn.fit(x_train_sc, y_train) \n",
    "\n",
    "# Obtenemos el accuracy del modelo en el set de validación\n",
    "print(knn.score(scaler.transform(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos predicciones con el modelo K-NN. Cuando escalamos los atributos de entrenamiento debemos usar el **mismo escalamiento** en los atributos para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred = knn.predict(scaler.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test), targets=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "print(nb.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test), targets=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, criterion='entropy')\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test), targets=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([t.feature_importances_ for t in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Listado de las 10 características más importantes\"\"\"\n",
    "for f in range(10):\n",
    "    print(\"{} caracterísitcas {} ({})\".format(f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualización del ranking de características\"\"\"\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.suptitle(\"Importancia de Atributos\")\n",
    "    plt.bar(range(x_train.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(x_train.shape[1]), indices)\n",
    "    plt.xlim([-1, x_train.shape[1]])\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "En esta sección revisaremos el uso de validación cruzada para la evaluación del rendimiento de los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn, x_train, y_train, cv=n_folds, scoring='accuracy')\n",
    "\n",
    "print('Accuracy: {:0.2f} +/- {:0.2f}'.format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Validación considerando el escalamiento. Incluimos el clasificador en un ```pipeline``` junto con el escalarado. Esto nos permite obtener el comportamiento de escalar también el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), knn)\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=n_folds, scoring='accuracy')\n",
    "\n",
    "print('Accuracy: {:0.2f} +/- {:0.2f}'.format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La función ```cross_val_score()``` realizar la validación cruzada utilizando una métrica única seleccionada a través del parámetro ```scoring```.\n",
    "\n",
    "- A diferencia, la función ```cross_validate()``` permite la evaluación y cálculo de múltiples métricas de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    dtree, x_train, y_train, \n",
    "    cv=n_folds,\n",
    "    scoring={'accuracy','f1_macro', 'f1_micro', 'f1_weighted'},\n",
    "    n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operador KFold como iterador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "# skf = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)  # Activamos shuffle\n",
    "skf = KFold(n_splits=n_folds, random_state=0)  # Activamos shuffle\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, (train_id, test_id) in enumerate(skf.split(X=features[features.columns[:-1]], y=features[features.columns[-1]])):\n",
    "    \n",
    "    x_train, y_train = features.iloc[train_id, :-1], features.iloc[train_id, -1]\n",
    "    x_test, y_test = features.iloc[test_id, :-1], features.iloc[test_id, -1]\n",
    "\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=3, algorithm='auto', n_jobs=2)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    \n",
    "#     scores = show_precision_recall(pred, y_test, targets=targets)\n",
    "#     print('Fold: {}'.format(i+1))\n",
    "#     print(scores)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
    "    \"\"\"\n",
    "    Crea un gráfico con los índices de la validación cruzada.\n",
    "    \n",
    "    \"\"\"\n",
    "    cmap_data = plt.cm.Paired\n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "    \n",
    "    # Genera la visualización para entrenamiento/validación para cada partición de la VC\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * X.shape[0])\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualiza los resultados\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "#     ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "#                c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['class']#, 'group']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Índice de Muestras', ylabel=\"Iteración CV\",\n",
    "           #ylim=[n_splits+2.2, -.2], xlim=[0, 100]\n",
    "          )\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = features[features.columns[:-1]].copy(), features[features.columns[-1]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax = plot_cv_indices(skf, X, y, ax=ax, n_splits=n_folds)\n",
    "    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "    # Make the legend fit\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=.7)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1e3, penalty='l2', solver='newton-cg', multi_class='auto')\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=10, random_state=0, tol=1e-5, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test), targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar uso de multiclase\n",
    "# https://scikit-learn.org/stable/modules/multiclass.html\n",
    "mc_svm = OneVsOneClassifier(SVC(C=1, gamma='auto', kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_svm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mc_svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Confusion matrix\n",
    "# # Check how to do ti using seaborn\n",
    "# # https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "# import itertools\n",
    "\n",
    "# def plot_confusion_matrix(cm, target_names=None, cmap=None, normalize=True, figsize=(6, 6)):\n",
    "\n",
    "#     title = 'Matriz de confusión', \n",
    "\n",
    "#     # Calculamos el accuracy para el clasificador\n",
    "#     accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "#     misclass = 1 - accuracy\n",
    "\n",
    "#     if cmap is None:\n",
    "#         cmap = plt.get_cmap('Blues')\n",
    "\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "#     ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     ax.set_title(title)\n",
    "#     cbar = ax.figure.colorbar(cm, ax=ax)\n",
    "#     cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "#     if target_names is not None:\n",
    "#         tick_marks = np.arange(len(target_names))\n",
    "#         plt.xticks(tick_marks, target_names, rotation=45)\n",
    "#         plt.yticks(tick_marks, target_names)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#     thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         if normalize:\n",
    "#             plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#         else:\n",
    "#             plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('Clase Real')\n",
    "#     plt.xlabel('Clase Predicha\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(corr_matrix, vmin=-1, cmap='coolwarm', annot=False, mask=mask);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
